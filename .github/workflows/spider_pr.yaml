name: Run Changed Spiders in Pull Requests

# Only run on pushes
on:
  pull_request:
    paths:
    - 'locations/spiders/*.py'

jobs:
  test-spider:
    runs-on: ubuntu-latest
    env:
      AWS_KEY: QUtJQVZFWlJZM1ozUjVFQ05YTTY=
      AWS_SEC: Nkl5citXTXE4dEsyS01DWHAxR1N1cFZSZWZqemZ4TFV2dDlNVDMxSQ==
      BUCKET: placescraper-results
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
    - name: Setup Python
      uses: actions/setup-python@master
      with:
        python-version: 3.7
    - name: Install pipenv
      run: |
        pip --quiet install pipenv
    - uses: actions/cache@v2
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/Pipfile.lock') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    - name: Install dependencies
      run: |
        pipenv --bare install --system --deploy
        sudo apt-get install jq
    - name: Run Scrapy check
      run: |
        scrapy check
    - name: Run spiders that changed
      shell: bash
      run: |
        PR_COMMENT_BODY="I ran the spiders in this pull request and got these results:\\n\\n|Spider|Results|Log|\\n|---|---|---|\\n"

        export AWS_ACCESS_KEY_ID=$(echo -n "${AWS_KEY}" | base64 --decode)
        export AWS_SECRET_ACCESS_KEY=$(echo -n "${AWS_SEC}" | base64 --decode)

        SPIDERS=$(curl -sL https://api.github.com/repos/alltheplaces/alltheplaces/pulls/${{ github.event.number }}/files | jq -r '.[].filename')

        RUN_DIR="${GITHUB_WORKSPACE}/output"
        EXIT_CODE=0
        for file_changed in $SPIDERS
        do
            if [[ $file_changed != locations/spiders/* ]]; then
                echo "${file_changed} is not a spider. Skipping."
                continue
            fi

            spider="${file_changed}"
            (>&2 echo "${spider} running ...")
            SPIDER_NAME=$(basename $spider)
            SPIDER_NAME=${SPIDER_NAME%.py}
            SPIDER_RUN_DIR="${RUN_DIR}/${SPIDER_NAME}"
            mkdir -p "${SPIDER_RUN_DIR}"

            LOGFILE="${SPIDER_RUN_DIR}/log.txt"
            OUTFILE="${SPIDER_RUN_DIR}/output.geojson"

            scrapy runspider \
                -t geojson \
                -o "file://${OUTFILE}" \
                --loglevel=INFO \
                --logfile="${LOGFILE}" \
                -s CLOSESPIDER_TIMEOUT=60 \
                -s CLOSESPIDER_ERRORCOUNT=1 \
                $spider

            FAILURE_REASON="success"
            if grep -q "Spider closed (closespider_errorcount)" $LOGFILE; then
                (>&2 echo "${spider} exited with errors")
                EXIT_CODE=1
                FAILURE_REASON="exception"
            elif grep -q "Spider closed (closespider_timeout)" $LOGFILE; then
                (>&2 echo "${spider} exited because of timeout")
                FAILURE_REASON="timeout"
            fi

            aws s3 cp --acl=public-read --only-show-errors ${LOGFILE} s3://${BUCKET}/ci/${GITHUB_RUN_ID}/${SPIDER_NAME}/log.txt
            LOGFILE_URL="https://${BUCKET}.s3.amazonaws.com/ci/${GITHUB_RUN_ID}/${SPIDER_NAME}/log.txt"

            echo "${spider} log: ${LOGFILE_URL}"

            if [ -f "$OUTFILE" ]; then
                FEATURE_COUNT=$(wc -l < ${OUTFILE} | tr -d ' ')
                
                if [ $FEATURE_COUNT == "0" ]; then
                    echo "${spider} has no output"
                    FAILURE_REASON="no output"
                    PR_COMMENT_BODY="${PR_COMMENT_BODY}|[\`$spider\`](https://github.com/${GITHUB_REPOSITORY}/blob/${GITHUB_SHA}/${spider})| (No Output) |Resulted in a \`${FAILURE_REASON}\` ([Log](${LOGFILE_URL}))|\\n"
                    EXIT_CODE=1
                    continue
                fi

                aws s3 cp --acl=public-read --only-show-errors ${OUTFILE} s3://${BUCKET}/ci/${GITHUB_RUN_ID}/${SPIDER_NAME}/output.geojson
                OUTFILE_URL="https://${BUCKET}.s3.amazonaws.com/ci/${GITHUB_RUN_ID}/${SPIDER_NAME}/output.geojson"

                if grep -q 'Stored geojson feed' $LOGFILE; then
                    echo "${spider} has ${FEATURE_COUNT} features: https://placescraper-results.s3.amazonaws.com/map.html?show=${OUTFILE_URL}"
                fi

                PR_COMMENT_BODY="${PR_COMMENT_BODY}|[\`$spider\`](https://github.com/${GITHUB_REPOSITORY}/blob/${GITHUB_SHA}/${spider})|[${FEATURE_COUNT} items](${OUTFILE_URL}) ([Map](https://placescraper-results.s3.amazonaws.com/map.html?show=${OUTFILE_URL}))|Resulted in a \`${FAILURE_REASON}\` ([Log](${LOGFILE_URL}))|\\n"
            else
                echo "${spider} has no output"
                FAILURE_REASON="no output"
                PR_COMMENT_BODY="${PR_COMMENT_BODY}|[\`$spider\`](https://github.com/${GITHUB_REPOSITORY}/blob/${GITHUB_SHA}/${spider})| (No Output) |Resulted in a \`${FAILURE_REASON}\` ([Log](${LOGFILE_URL}))|\\n"
                EXIT_CODE=1
            fi

            (>&2 echo "${spider} done")
        done

        if [[ ! "$(ls ${RUN_DIR})" ]]; then
            echo "Nothing ran. Exiting."
            echo $EXIT_CODE
        fi

        if [ -z "${{ secrets.GITHUB_TOKEN }}" ]; then
            echo "No GITHUB_TOKEN set"
        else
            if [ "${{ github.event.number }}" != "false" ]; then
                curl \
                    -s \
                    -XPOST \
                    -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                    -d "{\"body\":\"${PR_COMMENT_BODY}\"}" \
                    "https://api.github.com/repos/${GITHUB_REPOSITORY}/issues/${{ github.event.number }}/comments"
                echo "Added a comment to pull https://github.com/${GITHUB_REPOSITORY}/pull/${{ github.event.number }}"
            else
                echo "Not posting to GitHub because no pull event number set"
            fi
        fi

        exit $EXIT_CODE
